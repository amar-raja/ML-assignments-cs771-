{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "from scipy import linalg, sparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import numpy.random as rnd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[2]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAXIMIZATION STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxm_step(log_resp):\n",
    "    \n",
    "    n_samples, _ = X.shape\n",
    "    \n",
    "    #MEANS AND COVARIANCES OF EACH CLUSTER\n",
    "    means, covariances = gaussian_parameters(np.exp(log_resp))\n",
    "    \n",
    "    # CHOLESKY PRECISIONS\n",
    "    precisions_cholesky= precision_cholesky(covariances)\n",
    "    \n",
    "    return means,precisions_cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[3]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETURN LOG OF FIXED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_weights():\n",
    "        return np.log(fix_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[4]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALCULATE LOG OF DETERMINANT OF CHOLESKY PRECISIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_det_cholesky(matrix_chol, n_features):\n",
    "    log_det_chol = n_features * (np.log(matrix_chol))                   #NO OF FEATURES * LOG(CHOLESKY PRECISIONS)\n",
    "    return log_det_chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[5]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALCULATE THE LOG GAUSSIAN PROBABILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gaussian_prob(means, precisions_chol):\n",
    "    n_samples, n_features = X.shape\n",
    "    num_comp, _ = means.shape\n",
    "    \n",
    "    log_det = log_det_cholesky(precisions_chol, n_features)\n",
    "    precisions = precisions_chol ** 2\n",
    "    log_prob = (np.sum(means ** 2, 1) * precisions- 2 * np.dot(X, means.T * precisions)+ np.outer(np.einsum(\"ij,ij->i\", X, X), precisions))\n",
    "    \n",
    "    # Since we are using the precision of the Cholesky decomposition,\n",
    "    # - 0.5 * log_det_precision` becomes `+ log_det_precision_chol\n",
    "    \n",
    "    return -0.5 * (n_features * np.log(2 * np.pi) + log_prob) + log_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[6]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALCULATE WEIGHTED LOG PROBABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_log_prob(means,precisions_cholesky):\n",
    "    \n",
    "    #weighted log probabilities=  log gaussian probabilities + log weights\n",
    "    return log_gaussian_prob(means,precisions_cholesky) + log_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[7]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALCULATE LOG RESPONSIBILITIES OF SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_resp(means,precisions_cholesky):\n",
    "    \n",
    "    #weighted log probabilities\n",
    "    weighted_log_prob = weighted_log_prob(means,precisions_cholesky)\n",
    "    \n",
    "    #normalized log probabilities\n",
    "    log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
    "    \n",
    "    #CALCULATING THE LOG RESPONSIBILITIES\n",
    "    with np.errstate(under=\"ignore\"):\n",
    "        # ignore underflow\n",
    "        log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]\n",
    "    \n",
    "    #returning normalized log probabilities,log responsibilities\n",
    "    return log_prob_norm, log_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[8]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unction to do the estimation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_step(means,precisions_cholesky):\n",
    "    \n",
    "    #LOG PROBABILITY NORMALIZED AND LOG RESPONSIBILITIES\n",
    "    log_prob_norm, log_resp = log_prob_resp(means,precisions_cholesky)\n",
    "    \n",
    "    # MEAN OF LOG PROBABILITY NORAMALIZED AND LOG RESPONSIBILITIES\n",
    "    return np.mean(log_prob_norm), log_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[9]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOLESKY PRECISIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_cholesky(covariances):\n",
    "    \n",
    "    #if any covariance is found negative return error\n",
    "    if np.any(np.less_equal(covariances, 0.0)):\n",
    "        raise ValueError\n",
    "    \n",
    "    #colesky precisions\n",
    "    precisions_chol = 1.0 / np.sqrt(covariances)\n",
    "    \n",
    "    return precisions_chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[10]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PHERICAL COVARIANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covar(resp,nk,means):\n",
    "    n_c,n_f=means.shape\n",
    "    covar=np.empty((n_c,n_f,n_f))\n",
    "    spherical_cov=[]\n",
    "    \n",
    "    #for each cluster\n",
    "    for k in range(n_c):\n",
    "        \n",
    "        #calculating the full covariance\n",
    "        diff=X-means[k]\n",
    "        covar[k]=np.dot(resp[:,k]*diff.T,diff)/nk[k]\n",
    "        \n",
    "        #diagonal covariance and mean of diagonal elements to get the spherical covararince\n",
    "        s_co=np.diagonal(covar[k]*np.identity(2)).mean()\n",
    "        spherical_cov.append(s_co)\n",
    "        \n",
    "    spherical_cov=np.array(spherical_cov)\n",
    "    return spherical_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[11]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUSSIAN PARAMETERS OF EACH CLUSTER WITH GIVEN RESPONSIBILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_parameters(resp):\n",
    "    \n",
    "    #NO OF POINTS IN EACH CLUSTER\n",
    "    nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "    \n",
    "    #MEANS OF EACH CLUSTER\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "    \n",
    "    #covariances of each cluster\n",
    "    covariances = covar(resp, nk, means)\n",
    "    return means, covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[12]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    #NUMBER OF DATA POINTS\n",
    "    n_samples, _ = X.shape\n",
    "    \n",
    "    #ASSIGNING RESPONSIBILITES RANDOMLY \n",
    "    resp = np.random.rand(n_samples,num_comp)\n",
    "    \n",
    "    #NORMALIZING RESPONSIBILITIES\n",
    "    resp /= resp.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #MEANS AND COVARIANCES OF EACH CLUSTER BASED ON RESPONSIBILITIES\n",
    "    means, covariances = gaussian_parameters(resp)\n",
    "    \n",
    "    #CHOLESKY PRECISIONS\n",
    "    precisions_cholesky = precision_cholesky(covariances)\n",
    "    \n",
    "    return resp,means,precisions_cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[13]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(max_iter):\n",
    "    \n",
    "    n_samples, _ = X.shape\n",
    "    resp,means,precisions_cholesky=initialize_parameters()\n",
    "    lower_bound = -np.inf\n",
    "    tol=1e-5\n",
    "    for n_iter in range(1, max_iter + 1):\n",
    "        \n",
    "        #PREVIOUS ITERATIONS LOWER BOUND \n",
    "        prev_lower_bound = lower_bound\n",
    "        \n",
    "        #PERFORMING 'E' STEP\n",
    "        log_prob_norm, log_resp = (means,precisions_cholesky)\n",
    "        \n",
    "        #PERFORMING 'M' STEP\n",
    "        means,precisions_cholesky=maxm_step( log_resp)\n",
    "        \n",
    "        lower_bound = log_prob_norm\n",
    "        change = lower_bound - prev_lower_bound\n",
    "        \n",
    "        #TESTING CONVERGENCE\n",
    "        if abs(change) < tol:\n",
    "            converged = True\n",
    "            break\n",
    "    \n",
    "    #FINAL RESPONSIBILITIES OF EACH POINT\n",
    "    _, log_resp = (means,precisions_cholesky)\n",
    "    \n",
    "    return log_resp.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[14]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFigure( sizex = 7, sizey = 7 ):\n",
    "    fig = plt.figure( figsize = (sizex, sizey) )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2D( X, fig, color = 'r', marker = '+', size = 100, empty = False ):\n",
    "    plt.figure( fig.number )\n",
    "    if empty:\n",
    "        plt.scatter( X[:,0], X[:,1], s = size, facecolors = 'none', edgecolors = color, marker = marker  )\n",
    "    else:\n",
    "        plt.scatter( X[:,0], X[:,1], s = size, c = color, marker = marker )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSphericalData( d, n, mu, r ):\n",
    "    X = rnd.normal( 0, 1, (n, d) )\n",
    "    norms = lin.norm( X, axis = 1 )\n",
    "    X = X / norms[:, np.newaxis]\n",
    "    X = (X * r) + mu\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[15]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global X,num_comp,fix_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATING 3 CLUSTERS SYNTHETIC DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[16]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = np.array( [0,0] )\n",
    "mu2= np.array( [3.5,3.5] )\n",
    "mu3=np.array([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = genSphericalData( d, n, mu1, 1.9 )\n",
    "tmp2=genSphericalData( d, n, mu2,2)\n",
    "tmp3 = genSphericalData( d, n, mu3, 1.9 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack( (tmp1, tmp2,tmp3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lotting generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = getFigure( 8, 8 )\n",
    "plot2D( X, fig, size = 50, color = 'b', marker = 'o' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[17]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp=3\n",
    "fix_wts=np.array([0.33,0.33,0.33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[18]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STORING IN A DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDING LABEL COLUMN BY FIT PREDICT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=fit_predict(max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_labels = np.unique(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[19]:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOTTING CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = getFigure( 8, 8 )\n",
    "for i in u_labels:\n",
    "    plt.scatter(df[df['label'] == i].iloc[:,0],df[df['label'] == i].iloc[:,1],label = i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In[ ]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
